{
    "cells": [
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# Feature Engineering for Stock Price Prediction\n",
                "\n",
                "This notebook creates engineered features including:\n",
                "- Technical indicators (SMA, EMA, RSI, MACD, Bollinger Bands)\n",
                "- Lag features and rolling statistics\n",
                "- Volatility features\n",
                "- Target variable definitions"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "import pandas as pd\n",
                "import numpy as np\n",
                "import matplotlib.pyplot as plt\n",
                "import seaborn as sns\n",
                "from scipy.signal import argrelextrema\n",
                "import warnings\n",
                "warnings.filterwarnings('ignore')\n",
                "\n",
                "%matplotlib inline\n",
                "plt.rcParams['figure.figsize'] = (14, 6)"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 1. Load Data"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Load cleaned data from EDA\n",
                "df = pd.read_csv('../stock_data.csv', parse_dates=['dt'])\n",
                "df.set_index('dt', inplace=True)\n",
                "\n",
                "print(f\"Dataset shape: {df.shape}\")\n",
                "print(f\"Date range: {df.index.min()} to {df.index.max()}\")\n",
                "df.head()"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 2. Price-Based Features"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Daily returns\n",
                "df['daily_return'] = df['sp500'].pct_change()\n",
                "\n",
                "# Log returns\n",
                "df['log_return'] = np.log(df['sp500'] / df['sp500'].shift(1))\n",
                "\n",
                "# Price change\n",
                "df['price_change'] = df['sp500'].diff()\n",
                "\n",
                "# Percentage change over multiple periods\n",
                "for period in [3, 5, 10, 20]:\n",
                "    df[f'pct_change_{period}d'] = df['sp500'].pct_change(periods=period)\n",
                "    df[f'price_change_{period}d'] = df['sp500'].diff(periods=period)\n",
                "\n",
                "print(\"Price-based features created:\")\n",
                "print([col for col in df.columns if 'return' in col or 'change' in col])"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 3. Technical Indicators"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Simple Moving Averages\n",
                "for window in [5, 10, 20, 50, 200]:\n",
                "    df[f'SMA_{window}'] = df['sp500'].rolling(window=window).mean()\n",
                "    df[f'price_to_SMA_{window}'] = df['sp500'] / df[f'SMA_{window}']\n",
                "\n",
                "# Exponential Moving Averages\n",
                "for span in [12, 26]:\n",
                "    df[f'EMA_{span}'] = df['sp500'].ewm(span=span, adjust=False).mean()\n",
                "\n",
                "# MACD (Moving Average Convergence Divergence)\n",
                "df['MACD'] = df['EMA_12'] - df['EMA_26']\n",
                "df['MACD_signal'] = df['MACD'].ewm(span=9, adjust=False).mean()\n",
                "df['MACD_histogram'] = df['MACD'] - df['MACD_signal']\n",
                "\n",
                "print(\"\\nMoving averages and MACD created\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# RSI (Relative Strength Index)\n",
                "def calculate_rsi(prices, period=14):\n",
                "    delta = prices.diff()\n",
                "    gain = (delta.where(delta > 0, 0)).rolling(window=period).mean()\n",
                "    loss = (-delta.where(delta < 0, 0)).rolling(window=period).mean()\n",
                "    rs = gain / loss\n",
                "    rsi = 100 - (100 / (1 + rs))\n",
                "    return rsi\n",
                "\n",
                "df['RSI_14'] = calculate_rsi(df['sp500'], period=14)\n",
                "\n",
                "print(\"RSI calculated\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Bollinger Bands\n",
                "window = 20\n",
                "df['BB_middle'] = df['sp500'].rolling(window=window).mean()\n",
                "df['BB_std'] = df['sp500'].rolling(window=window).std()\n",
                "df['BB_upper'] = df['BB_middle'] + (2 * df['BB_std'])\n",
                "df['BB_lower'] = df['BB_middle'] - (2 * df['BB_std'])\n",
                "df['BB_width'] = df['BB_upper'] - df['BB_lower']\n",
                "df['BB_position'] = (df['sp500'] - df['BB_lower']) / (df['BB_upper'] - df['BB_lower'])\n",
                "\n",
                "print(\"Bollinger Bands calculated\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Visualize technical indicators\n",
                "fig, axes = plt.subplots(3, 1, figsize=(16, 12))\n",
                "\n",
                "# Price with moving averages\n",
                "axes[0].plot(df.index[-500:], df['sp500'][-500:], label='S&P 500', linewidth=1.5)\n",
                "axes[0].plot(df.index[-500:], df['SMA_20'][-500:], label='SMA 20', linewidth=1)\n",
                "axes[0].plot(df.index[-500:], df['SMA_50'][-500:], label='SMA 50', linewidth=1)\n",
                "axes[0].set_title('S&P 500 with Moving Averages (Last 500 Days)', fontweight='bold')\n",
                "axes[0].legend()\n",
                "axes[0].grid(True, alpha=0.3)\n",
                "\n",
                "# RSI\n",
                "axes[1].plot(df.index[-500:], df['RSI_14'][-500:], linewidth=1, color='purple')\n",
                "axes[1].axhline(70, color='red', linestyle='--', alpha=0.7, label='Overbought')\n",
                "axes[1].axhline(30, color='green', linestyle='--', alpha=0.7, label='Oversold')\n",
                "axes[1].set_title('RSI (14-day)', fontweight='bold')\n",
                "axes[1].set_ylim(0, 100)\n",
                "axes[1].legend()\n",
                "axes[1].grid(True, alpha=0.3)\n",
                "\n",
                "# MACD\n",
                "axes[2].plot(df.index[-500:], df['MACD'][-500:], label='MACD', linewidth=1)\n",
                "axes[2].plot(df.index[-500:], df['MACD_signal'][-500:], label='Signal', linewidth=1)\n",
                "axes[2].bar(df.index[-500:], df['MACD_histogram'][-500:], label='Histogram', alpha=0.3)\n",
                "axes[2].set_title('MACD', fontweight='bold')\n",
                "axes[2].legend()\n",
                "axes[2].grid(True, alpha=0.3)\n",
                "\n",
                "plt.tight_layout()\n",
                "plt.show()"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 4. Lag Features"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Lagged price features\n",
                "for lag in [1, 2, 3, 5, 10]:\n",
                "    df[f'sp500_lag_{lag}'] = df['sp500'].shift(lag)\n",
                "    df[f'return_lag_{lag}'] = df['daily_return'].shift(lag)\n",
                "    df[f'vix_lag_{lag}'] = df['vix'].shift(lag)\n",
                "\n",
                "# Lagged volume\n",
                "for lag in [1, 2, 5]:\n",
                "    df[f'volume_lag_{lag}'] = df['sp500_volume'].shift(lag)\n",
                "\n",
                "print(f\"Lag features created: {len([col for col in df.columns if 'lag' in col])} features\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 5. Rolling Window Features"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Rolling statistics\n",
                "for window in [5, 10, 20]:\n",
                "    df[f'rolling_mean_{window}'] = df['sp500'].rolling(window=window).mean()\n",
                "    df[f'rolling_std_{window}'] = df['sp500'].rolling(window=window).std()\n",
                "    df[f'rolling_min_{window}'] = df['sp500'].rolling(window=window).min()\n",
                "    df[f'rolling_max_{window}'] = df['sp500'].rolling(window=window).max()\n",
                "    df[f'rolling_median_{window}'] = df['sp500'].rolling(window=window).median()\n",
                "    \n",
                "    # Position relative to rolling window\n",
                "    df[f'position_in_range_{window}'] = (df['sp500'] - df[f'rolling_min_{window}']) / \\\n",
                "                                         (df[f'rolling_max_{window}'] - df[f'rolling_min_{window}'])\n",
                "\n",
                "print(f\"Rolling window features created\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 6. Volatility Features"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Historical volatility (rolling std of returns)\n",
                "for window in [5, 10, 20]:\n",
                "    df[f'volatility_{window}'] = df['daily_return'].rolling(window=window).std() * np.sqrt(252)\n",
                "\n",
                "# VIX changes\n",
                "df['vix_change'] = df['vix'].diff()\n",
                "df['vix_pct_change'] = df['vix'].pct_change()\n",
                "df['vix_momentum'] = df['vix'].diff(5)\n",
                "\n",
                "# Volatility ratio (short-term vs long-term)\n",
                "df['volatility_ratio'] = df['volatility_5'] / df['volatility_20']\n",
                "\n",
                "print(\"Volatility features created\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 7. Volume Features"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Volume ratios\n",
                "df['volume_ma_20'] = df['sp500_volume'].rolling(window=20).mean()\n",
                "df['volume_ratio'] = df['sp500_volume'] / df['volume_ma_20']\n",
                "df['volume_momentum'] = df['sp500_volume'].diff(5)\n",
                "df['volume_change'] = df['sp500_volume'].pct_change()\n",
                "\n",
                "print(\"Volume features created\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 8. Temporal Features"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Extract temporal features\n",
                "df['day_of_week'] = df.index.dayofweek\n",
                "df['month'] = df.index.month\n",
                "df['quarter'] = df.index.quarter\n",
                "df['day_of_month'] = df.index.day\n",
                "df['week_of_year'] = df.index.isocalendar().week\n",
                "df['is_month_end'] = df.index.is_month_end.astype(int)\n",
                "df['is_quarter_end'] = df.index.is_quarter_end.astype(int)\n",
                "\n",
                "print(\"Temporal features created\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 9. Target Variable Engineering\n",
                "\n",
                "We'll create multiple target variables for different prediction tasks"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# REGRESSION TARGETS\n",
                "\n",
                "# Next day price\n",
                "df['target_price_next_day'] = df['sp500'].shift(-1)\n",
                "\n",
                "# 5-day ahead price\n",
                "df['target_price_5day'] = df['sp500'].shift(-5)\n",
                "\n",
                "# Next day return\n",
                "df['target_return_next_day'] = df['daily_return'].shift(-1)\n",
                "\n",
                "print(\"Regression targets created\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# CLASSIFICATION TARGETS\n",
                "\n",
                "# Binary direction (next day)\n",
                "df['target_direction_next_day'] = (df['sp500'].shift(-1) > df['sp500']).astype(int)\n",
                "\n",
                "# Binary direction (5-day)\n",
                "df['target_direction_5day'] = (df['sp500'].shift(-5) > df['sp500']).astype(int)\n",
                "\n",
                "# Multi-class direction (-1: down, 0: flat, 1: up)\n",
                "threshold = 0.005  # 0.5% threshold for \"flat\"\n",
                "next_return = df['daily_return'].shift(-1)\n",
                "df['target_multiclass'] = 0\n",
                "df.loc[next_return > threshold, 'target_multiclass'] = 1\n",
                "df.loc[next_return < -threshold, 'target_multiclass'] = -1\n",
                "\n",
                "print(f\"\\nDirection distribution:\")\n",
                "print(df['target_direction_next_day'].value_counts())\n",
                "print(f\"\\nMulti-class distribution:\")\n",
                "print(df['target_multiclass'].value_counts())"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# BUY/SELL/HOLD SIGNALS based on local extrema\n",
                "def identify_signals(prices, order=5):\n",
                "    \"\"\"\n",
                "    Identify buy/sell signals based on local minima/maxima\n",
                "    order: how many points on each side to compare\n",
                "    \"\"\"\n",
                "    signals = np.zeros(len(prices))\n",
                "    \n",
                "    # Find local minima (BUY signals)\n",
                "    local_min = argrelextrema(prices.values, np.less_equal, order=order)[0]\n",
                "    signals[local_min] = 1  # BUY\n",
                "    \n",
                "    # Find local maxima (SELL signals)\n",
                "    local_max = argrelextrema(prices.values, np.greater_equal, order=order)[0]\n",
                "    signals[local_max] = -1  # SELL\n",
                "    \n",
                "    return signals\n",
                "\n",
                "df['target_signals'] = identify_signals(df['sp500'], order=10)\n",
                "\n",
                "print(f\"\\nSignals distribution:\")\n",
                "print(f\"BUY signals: {(df['target_signals'] == 1).sum()}\")\n",
                "print(f\"SELL signals: {(df['target_signals'] == -1).sum()}\")\n",
                "print(f\"HOLD: {(df['target_signals'] == 0).sum()}\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Visualize signals\n",
                "fig, ax = plt.subplots(figsize=(16, 6))\n",
                "\n",
                "# Plot recent data\n",
                "recent = df.tail(1000)\n",
                "ax.plot(recent.index, recent['sp500'], label='S&P 500', linewidth=1.5, color='blue', alpha=0.7)\n",
                "\n",
                "# Plot BUY signals\n",
                "buy_signals = recent[recent['target_signals'] == 1]\n",
                "ax.scatter(buy_signals.index, buy_signals['sp500'], color='green', marker='^', \n",
                "           s=100, label='BUY Signals', zorder=5)\n",
                "\n",
                "# Plot SELL signals\n",
                "sell_signals = recent[recent['target_signals'] == -1]\n",
                "ax.scatter(sell_signals.index, sell_signals['sp500'], color='red', marker='v', \n",
                "           s=100, label='SELL Signals', zorder=5)\n",
                "\n",
                "ax.set_title('BUY/SELL Signals Based on Local Extrema (Last 1000 Days)', fontweight='bold', fontsize=14)\n",
                "ax.set_xlabel('Date')\n",
                "ax.set_ylabel('S&P 500 Price')\n",
                "ax.legend()\n",
                "ax.grid(True, alpha=0.3)\n",
                "plt.tight_layout()\n",
                "plt.show()"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 10. Feature Summary and Data Quality"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "print(\"=\"*80)\n",
                "print(\"FEATURE ENGINEERING SUMMARY\")\n",
                "print(\"=\"*80)\n",
                "\n",
                "print(f\"\\nTotal features created: {len(df.columns)}\")\n",
                "print(f\"Date range: {df.index.min()} to {df.index.max()}\")\n",
                "print(f\"Total observations: {len(df):,}\")\n",
                "\n",
                "# Count features by category\n",
                "categories = {\n",
                "    'Price-based': ['return', 'change'],\n",
                "    'Technical Indicators': ['SMA', 'EMA', 'MACD', 'RSI', 'BB'],\n",
                "    'Lag Features': ['lag'],\n",
                "    'Rolling Features': ['rolling'],\n",
                "    'Volatility': ['volatility', 'vix'],\n",
                "    'Volume': ['volume'],\n",
                "    'Temporal': ['day', 'month', 'quarter', 'week'],\n",
                "    'Target Variables': ['target']\n",
                "}\n",
                "\n",
                "for category, keywords in categories.items():\n",
                "    count = sum(1 for col in df.columns if any(kw in col.lower() for kw in keywords))\n",
                "    print(f\"{category}: {count} features\")\n",
                "\n",
                "# Missing values after feature engineering\n",
                "missing = df.isnull().sum()\n",
                "print(f\"\\nFeatures with missing values: {(missing > 0).sum()}\")\n",
                "print(f\"Max missing count: {missing.max()} ({missing.max()/len(df)*100:.2f}%)\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 11. Handle Missing Values and Save"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Drop rows with missing values (mostly from rolling windows at start)\n",
                "print(f\"Rows before cleaning: {len(df):,}\")\n",
                "df_clean = df.dropna()\n",
                "print(f\"Rows after cleaning: {len(df_clean):,}\")\n",
                "print(f\"Rows removed: {len(df) - len(df_clean):,}\")\n",
                "\n",
                "# Alternative: could use forward fill for specific features\n",
                "# df_clean = df.fillna(method='ffill').dropna()"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Save engineered features\n",
                "output_path = '../data/processed/features_engineered.csv'\n",
                "df_clean.to_csv(output_path)\n",
                "print(f\"\\nEngineered features saved to: {output_path}\")\n",
                "print(f\"Final dataset shape: {df_clean.shape}\")\n",
                "print(f\"Features: {df_clean.shape[1]} columns\")\n",
                "print(f\"Date range: {df_clean.index.min()} to {df_clean.index.max()}\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Display sample of engineered features\n",
                "feature_cols = [col for col in df_clean.columns if 'target' not in col]\n",
                "print(f\"\\nSample of engineered features (first 5 rows, random 10 features):\")\n",
                "sample_features = np.random.choice(feature_cols, size=min(10, len(feature_cols)), replace=False)\n",
                "df_clean[sample_features].head()"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 12. Feature Correlation with Targets"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Calculate correlation with regression target\n",
                "target_col = 'target_return_next_day'\n",
                "correlations = df_clean.corr()[target_col].sort_values(ascending=False)\n",
                "\n",
                "print(f\"\\nTop 20 features correlated with {target_col}:\")\n",
                "print(correlations.head(20))\n",
                "\n",
                "print(f\"\\nBottom 20 features (negative correlation):\")\n",
                "print(correlations.tail(20))"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Visualize top correlations\n",
                "top_features = correlations.head(15).index.tolist()\n",
                "top_features = [f for f in top_features if f != target_col]\n",
                "\n",
                "plt.figure(figsize=(10, 8))\n",
                "sns.barplot(x=correlations[top_features].values, y=top_features, palette='viridis')\n",
                "plt.title(f'Top Features Correlated with {target_col}', fontweight='bold', fontsize=13)\n",
                "plt.xlabel('Correlation Coefficient')\n",
                "plt.tight_layout()\n",
                "plt.show()"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## Next Steps\n",
                "\n",
                "With engineered features ready, you can now:\n",
                "1. Split data temporally (use `src/preprocessing.py`)\n",
                "2. Train baseline models for benchmarking\n",
                "3. Train XGBoost/LightGBM models\n",
                "4. Train LSTM/GRU deep learning models\n",
                "5. Evaluate and compare models\n",
                "6. Backtest trading strategies"
            ]
        }
    ],
    "metadata": {
        "kernelspec": {
            "display_name": "Python 3",
            "language": "python",
            "name": "python3"
        },
        "language_info": {
            "codemirror_mode": {
                "name": "ipython",
                "version": 3
            },
            "file_extension": ".py",
            "mimetype": "text/x-python",
            "name": "python",
            "nbconvert_exporter": "python",
            "pygments_lexer": "ipython3",
            "version": "3.8.0"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 4
}